{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mesa\n",
    "import math\n",
    "from enum import Enum\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "ITERATIONS = 100000\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "echo_party is the majority party. To get liberal majority results. Run with echo_party = 'liberal'. For conservatiev results, run with echo_party = 'conservative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo_party = 'liberal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the logistic regression model to map morals to emotions\n",
    "lrmodel = pickle.load(open('./moral2emotelr.pkl', 'rb'))\n",
    "moral_categories = ['purity', 'authority', 'fairness', 'degradation', 'care', \n",
    "                    'loyalty', 'subversion', 'cheating', 'harm', 'betrayal']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.14834134,  0.37811929,  1.58736116, -1.36935101,  1.95219789,\n",
       "         1.8168247 , -1.1393514 , -2.13577438, -2.34801116, -0.9017263 ]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrmodel.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate graphs and centrality statistics at the beginning of each sim.\n",
    "class GraphHolder:\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_nodes=10, \n",
    "        avg_node_degree=3, \n",
    "        iter = ITERATIONS,\n",
    "    ):\n",
    "        self.G_ = []\n",
    "        self.degree_ = []\n",
    "        self.eigen_ = []\n",
    "        self.betweenness_ = []\n",
    "        \n",
    "        for _ in range(iter):\n",
    "            G = nx.erdos_renyi_graph(n=num_nodes, p=1/avg_node_degree)\n",
    "            #G = nx.complete_graph(num_nodes)\n",
    "            self.G_.append(G)\n",
    "            deg = nx.degree_centrality(G)\n",
    "            # networkx degree normalizes degree by dividing by |V|-1. Undoing that normalization:\n",
    "            degree_renorm = {key:(val*(num_nodes - 1)) for key, val in deg.items()}\n",
    "            self.degree_.append(degree_renorm)\n",
    "            #self.eigen_.append(nx.eigenvector_centrality(G))\n",
    "            #self.betweenness_.append(nx.betweenness_centrality(G))\n",
    "            \n",
    "        self.G = {idx: i for idx, i in enumerate(self.G_)}\n",
    "        self.degree = {idx: i for idx, i in enumerate(self.degree_)}\n",
    "        #self.eigen = {idx: i for idx, i in enumerate(self.eigen_)}\n",
    "        #self.betweenness = {idx: i for idx, i in enumerate(self.betweenness_)}\n",
    "    #self.degre\n",
    "\n",
    "class State(Enum):\n",
    "    READ = 1\n",
    "    UNREAD = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "GH = GraphHolder()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the Agent Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmoAgent(mesa.Agent):\n",
    "    def __init__(\n",
    "        self,\n",
    "        unique_id,\n",
    "        model,\n",
    "        read_state,\n",
    "        initial_state,\n",
    "        degree_centrality,\n",
    "        initial_message,\n",
    "        party,\n",
    "    ):\n",
    "        super().__init__(unique_id, model)\n",
    "\n",
    "        self.initial_state = initial_state\n",
    "        self.current_state = initial_state\n",
    "        self.state_cache = list(initial_state)\n",
    "        self.degree = degree_centrality\n",
    "        self.susceptibility = 1/(degree_centrality+1)\n",
    "        self.read_state = read_state\n",
    "        self.initial_message = initial_message\n",
    "        self.party = party\n",
    "    \n",
    "    def look_at_neighbors(self):\n",
    "        neighbors_nodes = self.model.grid.get_neighbors(self.pos, include_center=False)\n",
    "        read_neighbors = [\n",
    "            agent\n",
    "            for agent in self.model.grid.get_cell_list_contents(neighbors_nodes)\n",
    "            if agent.read_state is State.READ\n",
    "        ]\n",
    "        \n",
    "        comments = [a.current_state for a in read_neighbors]\n",
    "        if len(comments) == 0:\n",
    "            mean_comments = np.NAN\n",
    "        elif len(comments) == 1:\n",
    "            mean_comments = comments[0]\n",
    "        else:\n",
    "            mean_comments = np.mean(comments, axis = 0)\n",
    "        return mean_comments                    \n",
    "            \n",
    "    def read_messages_and_post(self):\n",
    "        mean_comments = self.look_at_neighbors()\n",
    "        if mean_comments is np.NAN:\n",
    "            self.current_state = np.tanh(self.initial_state + (self.susceptibility*self.initial_message)).reshape(1,10)\n",
    "            self.read_state = State.READ\n",
    "        else:\n",
    "            self.current_state = np.tanh(self.initial_state + (self.susceptibility*self.initial_message + mean_comments)).reshape(1,10)\n",
    "            self.read_state = State.READ\n",
    "        self.state_cache.append(self.current_state)\n",
    "    \n",
    "    def step(self):\n",
    "        self.read_messages_and_post()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions and the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opposition_party(echo_party):\n",
    "    if echo_party == 'conservative':\n",
    "        return 'liberal'\n",
    "    elif echo_party == 'liberal':\n",
    "        return 'conservative'\n",
    "\n",
    "def gen_political_agent(echo_party):\n",
    "    if echo_party == 'conservative':\n",
    "        # Rep - higher authority & Purity\n",
    "        poli_init = np.concatenate([np.random.uniform(low=0.5, high=1, size=(1)), # purity\n",
    "                    np.random.uniform(low=0.5, high =1, size= (1)), #authority\n",
    "                    np.random.uniform(low=0, high=1, size=(1)), #fairness\n",
    "                    np.random.uniform(low=0.5, high=1, size=(1)), # degradation\n",
    "                    np.random.uniform(low=0, high=1, size=(1)), # care\n",
    "                    np.random.uniform(low=0, high=1, size=(1)), # loyalty\n",
    "                    np.random.uniform(low=0.5, high=1, size=(1)), # subversion\n",
    "                    np.random.uniform(low=0, high=1, size=(1)), # cheating\n",
    "                    np.random.uniform(low=0, high=1, size=(1)), # harm\n",
    "                    np.random.uniform(low=0, high=1, size=(1))]).reshape(1,10) #betrayal\n",
    "    elif echo_party == 'liberal':\n",
    "        # Dem: higher fairness/harm & fairness/cheating\n",
    "        poli_init = np.concatenate([np.random.uniform(low=0, high=1, size=(1)), # purity\n",
    "                    np.random.uniform(low=0, high =1, size= (1)), #authority\n",
    "                    np.random.uniform(low=0.5, high=1, size=(1)), #fairness\n",
    "                    np.random.uniform(low=0, high=1, size=(1)), # degradation\n",
    "                    np.random.uniform(low=0.5, high=1, size=(1)), # care\n",
    "                    np.random.uniform(low=0, high=1, size=(1)), # loyalty\n",
    "                    np.random.uniform(low=0, high=1, size=(1)), # subversion\n",
    "                    np.random.uniform(low=0.5, high=1, size=(1)), # cheating\n",
    "                    np.random.uniform(low=0.5, high=1, size=(1)), # harm\n",
    "                    np.random.uniform(low=0, high=1, size=(1))]).reshape(1,10) #betrayal\n",
    "    else:\n",
    "        TypeError('Must be liberal or conservative')\n",
    "    return poli_init\n",
    "\n",
    "def number_state(model, state):\n",
    "    return sum(1 for a in model.grid.get_all_cell_contents() if a.read_state is state)\n",
    "\n",
    "def number_read(model):\n",
    "    return number_state(model, State.READ)\n",
    "\n",
    "def mean_morality(model):\n",
    "    morality = [a.current_state for a in model.grid.get_all_cell_contents()]\n",
    "    mean_morality = np.mean(morality, axis = 0)\n",
    "    return mean_morality\n",
    "    \n",
    "class MoralPosts(mesa.Model):\n",
    "    \"\"\"A virus model with some number of agents\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        id,\n",
    "        initial_message,\n",
    "        G,\n",
    "        degree,\n",
    "        echo_party,\n",
    "    ):\n",
    "        self.degree = degree\n",
    "        self.id = id\n",
    "        self.G = G\n",
    "        self.initial_message = initial_message\n",
    "        self.n_iter = 10\n",
    "        self.iter_counter = 0\n",
    "        self.grid = mesa.space.NetworkGrid(self.G)\n",
    "        self.schedule = mesa.time.RandomActivation(self)\n",
    "        self.echo_party = echo_party\n",
    "        self.opposition = opposition_party(self.echo_party)\n",
    "        \n",
    "        self.datacollector = mesa.DataCollector(\n",
    "            model_reporters={\"Read\": number_read,\n",
    "                             'Mean_morality':mean_morality},\n",
    "            agent_reporters={\"Morals\": lambda _: _.current_state,\n",
    "                             \"Degree\": lambda _: _.degree,\n",
    "                             \"Party\": lambda _: _.party},\n",
    "        )\n",
    "\n",
    "        opposition_member = np.random.randint(low=0, high=10, size = None)\n",
    "        for i, node in enumerate(self.G.nodes()):\n",
    "            if i == opposition_member:\n",
    "                a = EmoAgent(\n",
    "                    i,\n",
    "                    self,\n",
    "                    State.UNREAD,\n",
    "                    gen_political_agent(self.opposition),\n",
    "                    self.degree[i],\n",
    "                    self.initial_message,\n",
    "                    self.opposition\n",
    "                )\n",
    "                self.schedule.add(a)\n",
    "                # Add the agent to the node\n",
    "                self.grid.place_agent(a, node)            \n",
    "            else:\n",
    "                a = EmoAgent(\n",
    "                    i,\n",
    "                    self,\n",
    "                    State.UNREAD,\n",
    "                    gen_political_agent(self.echo_party),\n",
    "                    self.degree[i],\n",
    "                    self.initial_message,\n",
    "                    self.echo_party\n",
    "                )\n",
    "                self.schedule.add(a)\n",
    "                # Add the agent to the node\n",
    "                self.grid.place_agent(a, node)\n",
    "            \n",
    "        self.running = True\n",
    "        self.datacollector.collect(self)\n",
    "\n",
    "        #nodes = list(self.G)\n",
    "        #angry_nodes = self.random.sample(nodes, 1)\n",
    "        #for a in self.grid.get_cell_list_contents(angry_nodes):\n",
    "        #    a.state = State.ANGRY\n",
    "    \n",
    "    def new_post(self):\n",
    "        for a in self.grid.get_cell_list_contents(self.G.nodes()):\n",
    "            a.read_state = State.UNREAD\n",
    "\n",
    "    def step(self):\n",
    "        self.schedule.step()\n",
    "        self.datacollector.collect(self)\n",
    "        #self.new_post()\n",
    "\n",
    "    def run_model(self):\n",
    "        self.step()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evanwilliams/.pyenv/versions/3.9.1/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/evanwilliams/.pyenv/versions/3.9.1/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/evanwilliams/.pyenv/versions/3.9.1/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/evanwilliams/.pyenv/versions/3.9.1/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/evanwilliams/.pyenv/versions/3.9.1/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/evanwilliams/.pyenv/versions/3.9.1/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/evanwilliams/.pyenv/versions/3.9.1/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/evanwilliams/.pyenv/versions/3.9.1/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/evanwilliams/.pyenv/versions/3.9.1/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/evanwilliams/.pyenv/versions/3.9.1/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/evanwilliams/.pyenv/versions/3.9.1/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/evanwilliams/.pyenv/versions/3.9.1/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/evanwilliams/.pyenv/versions/3.9.1/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/evanwilliams/.pyenv/versions/3.9.1/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/evanwilliams/.pyenv/versions/3.9.1/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/evanwilliams/.pyenv/versions/3.9.1/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/evanwilliams/.pyenv/versions/3.9.1/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/evanwilliams/.pyenv/versions/3.9.1/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/evanwilliams/.pyenv/versions/3.9.1/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/evanwilliams/.pyenv/versions/3.9.1/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "final_stats = []\n",
    "graph_list = GH.G\n",
    "degree_list = GH.degree\n",
    "\n",
    "for initial_message in (np.eye(10)):\n",
    "    initial_message = initial_message.reshape(1, 10)\n",
    "    initial_morality = []\n",
    "    final_morality = []\n",
    "    initial_mean_morality = []\n",
    "    final_mean_morality = []\n",
    "    degree_cache = []\n",
    "    party_cache = []\n",
    "    for idx in range(ITERATIONS):\n",
    "        MP = MoralPosts(0, initial_message, G=graph_list[idx], degree = degree_list[idx], echo_party=echo_party)\n",
    "        MP.run_model()\n",
    "        # collect results\n",
    "        mean_moral_states = MP.datacollector.get_model_vars_dataframe()\n",
    "        initial_mean_morality.append(mean_moral_states.iloc[0].Mean_morality)\n",
    "        final_mean_morality.append(mean_moral_states.iloc[1].Mean_morality)\n",
    "        agent_states = pd.DataFrame(MP.datacollector.get_agent_vars_dataframe().to_records())\n",
    "        initial_morality.append(np.concatenate(agent_states[agent_states.Step == 0]['Morals'].tolist()))\n",
    "        final_morality.append(np.concatenate(agent_states[agent_states.Step == 1]['Morals'].tolist()))\n",
    "        degree_cache.append(agent_states[agent_states.Step == 0]['Degree'].tolist())\n",
    "        party_cache.append(agent_states[agent_states.Step == 0]['Party'].tolist())\n",
    "    \n",
    "    initial_morality = np.concatenate(initial_morality)\n",
    "    final_morality = np.concatenate(final_morality)\n",
    "    im_pred = lrmodel.predict(initial_morality)\n",
    "    fn_pred = lrmodel.predict(final_morality)\n",
    "    degree_cache = [item for sublist in degree_cache for item in sublist]\n",
    "    party_cache = [item for sublist in party_cache for item in sublist]\n",
    "\n",
    "    uh = pd.DataFrame({'initial':im_pred, 'final':fn_pred})\n",
    "    uh['prod'] = uh.final * uh.initial\n",
    "    uh['changed'] = np.where(uh['prod'] == -1, 1, 0)\n",
    "    uh['positive_change'] = np.where(uh['changed'] ==uh['final'], 1, 0)\n",
    "    uh['neg_change'] = 1*(uh.changed != uh.positive_change)\n",
    "    uh['degree'] = degree_cache\n",
    "    uh['party'] = party_cache\n",
    "    uh['echo'] = echo_party\n",
    "    minority = uh[uh['party'] != uh['echo']].copy()\n",
    "    minority = minority[minority['changed'] == 1].copy()\n",
    "    \n",
    "    final_stats.append({'trials': uh.shape[0],\n",
    "                        'initial_pos':(uh['initial']==1).sum(),\n",
    "                        'initial_neg':(uh['initial']==-1).sum(),\n",
    "                        'final_pos':(uh['final']==1).sum(),\n",
    "                        'final_neg':(uh['final']==-1).sum(),\n",
    "                        'changes':uh['changed'].sum(),\n",
    "                        'pos_changes':uh['positive_change'].sum(),\n",
    "                        'neg_changes':uh['changed'].sum() - uh['positive_change'].sum(),\n",
    "                        'pos_correlation':uh['degree'].corr(uh['positive_change']),\n",
    "                        'neg_correlation':uh['degree'].corr(uh['neg_change']),\n",
    "                        'minority_pos_changes':minority.positive_change.sum(),\n",
    "                        'minority_neg_changes':minority.neg_change.sum(),})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame(final_stats)\n",
    "out['morals'] = moral_categories\n",
    "out.to_csv('../results/liberal_maj_100k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trials</th>\n",
       "      <th>initial_pos</th>\n",
       "      <th>initial_neg</th>\n",
       "      <th>final_pos</th>\n",
       "      <th>final_neg</th>\n",
       "      <th>changes</th>\n",
       "      <th>pos_changes</th>\n",
       "      <th>neg_changes</th>\n",
       "      <th>pos_correlation</th>\n",
       "      <th>neg_correlation</th>\n",
       "      <th>minority_pos_changes</th>\n",
       "      <th>minority_neg_changes</th>\n",
       "      <th>morals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000000</td>\n",
       "      <td>423451</td>\n",
       "      <td>576549</td>\n",
       "      <td>614001</td>\n",
       "      <td>385999</td>\n",
       "      <td>234936</td>\n",
       "      <td>212743</td>\n",
       "      <td>22193</td>\n",
       "      <td>-0.107204</td>\n",
       "      <td>0.037859</td>\n",
       "      <td>12215</td>\n",
       "      <td>3102</td>\n",
       "      <td>purity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000000</td>\n",
       "      <td>423517</td>\n",
       "      <td>576483</td>\n",
       "      <td>439231</td>\n",
       "      <td>560769</td>\n",
       "      <td>139888</td>\n",
       "      <td>77801</td>\n",
       "      <td>62087</td>\n",
       "      <td>-0.010993</td>\n",
       "      <td>0.037896</td>\n",
       "      <td>5061</td>\n",
       "      <td>6860</td>\n",
       "      <td>authority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000000</td>\n",
       "      <td>422685</td>\n",
       "      <td>577315</td>\n",
       "      <td>487214</td>\n",
       "      <td>512786</td>\n",
       "      <td>165711</td>\n",
       "      <td>115120</td>\n",
       "      <td>50591</td>\n",
       "      <td>-0.066576</td>\n",
       "      <td>0.043837</td>\n",
       "      <td>11501</td>\n",
       "      <td>4232</td>\n",
       "      <td>fairness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000000</td>\n",
       "      <td>424306</td>\n",
       "      <td>575694</td>\n",
       "      <td>270778</td>\n",
       "      <td>729222</td>\n",
       "      <td>189106</td>\n",
       "      <td>17789</td>\n",
       "      <td>171317</td>\n",
       "      <td>0.025452</td>\n",
       "      <td>-0.042556</td>\n",
       "      <td>1445</td>\n",
       "      <td>14344</td>\n",
       "      <td>degradation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000000</td>\n",
       "      <td>423439</td>\n",
       "      <td>576561</td>\n",
       "      <td>507088</td>\n",
       "      <td>492912</td>\n",
       "      <td>176845</td>\n",
       "      <td>130247</td>\n",
       "      <td>46598</td>\n",
       "      <td>-0.081192</td>\n",
       "      <td>0.043186</td>\n",
       "      <td>13601</td>\n",
       "      <td>3902</td>\n",
       "      <td>care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000000</td>\n",
       "      <td>423529</td>\n",
       "      <td>576471</td>\n",
       "      <td>592703</td>\n",
       "      <td>407297</td>\n",
       "      <td>214848</td>\n",
       "      <td>192011</td>\n",
       "      <td>22837</td>\n",
       "      <td>-0.093691</td>\n",
       "      <td>0.035916</td>\n",
       "      <td>15331</td>\n",
       "      <td>1806</td>\n",
       "      <td>loyalty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000000</td>\n",
       "      <td>423057</td>\n",
       "      <td>576943</td>\n",
       "      <td>293219</td>\n",
       "      <td>706781</td>\n",
       "      <td>175394</td>\n",
       "      <td>22778</td>\n",
       "      <td>152616</td>\n",
       "      <td>0.026915</td>\n",
       "      <td>-0.032399</td>\n",
       "      <td>1773</td>\n",
       "      <td>13037</td>\n",
       "      <td>subversion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000000</td>\n",
       "      <td>423656</td>\n",
       "      <td>576344</td>\n",
       "      <td>291788</td>\n",
       "      <td>708212</td>\n",
       "      <td>187912</td>\n",
       "      <td>28022</td>\n",
       "      <td>159890</td>\n",
       "      <td>0.028520</td>\n",
       "      <td>-0.056449</td>\n",
       "      <td>1150</td>\n",
       "      <td>20679</td>\n",
       "      <td>cheating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000000</td>\n",
       "      <td>423515</td>\n",
       "      <td>576485</td>\n",
       "      <td>281292</td>\n",
       "      <td>718708</td>\n",
       "      <td>195291</td>\n",
       "      <td>26534</td>\n",
       "      <td>168757</td>\n",
       "      <td>0.029877</td>\n",
       "      <td>-0.062642</td>\n",
       "      <td>1073</td>\n",
       "      <td>22308</td>\n",
       "      <td>harm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000000</td>\n",
       "      <td>423424</td>\n",
       "      <td>576576</td>\n",
       "      <td>309840</td>\n",
       "      <td>690160</td>\n",
       "      <td>165172</td>\n",
       "      <td>25794</td>\n",
       "      <td>139378</td>\n",
       "      <td>0.025047</td>\n",
       "      <td>-0.021635</td>\n",
       "      <td>1379</td>\n",
       "      <td>14462</td>\n",
       "      <td>betrayal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    trials  initial_pos  initial_neg  final_pos  final_neg  changes  \\\n",
       "0  1000000       423451       576549     614001     385999   234936   \n",
       "1  1000000       423517       576483     439231     560769   139888   \n",
       "2  1000000       422685       577315     487214     512786   165711   \n",
       "3  1000000       424306       575694     270778     729222   189106   \n",
       "4  1000000       423439       576561     507088     492912   176845   \n",
       "5  1000000       423529       576471     592703     407297   214848   \n",
       "6  1000000       423057       576943     293219     706781   175394   \n",
       "7  1000000       423656       576344     291788     708212   187912   \n",
       "8  1000000       423515       576485     281292     718708   195291   \n",
       "9  1000000       423424       576576     309840     690160   165172   \n",
       "\n",
       "   pos_changes  neg_changes  pos_correlation  neg_correlation  \\\n",
       "0       212743        22193        -0.107204         0.037859   \n",
       "1        77801        62087        -0.010993         0.037896   \n",
       "2       115120        50591        -0.066576         0.043837   \n",
       "3        17789       171317         0.025452        -0.042556   \n",
       "4       130247        46598        -0.081192         0.043186   \n",
       "5       192011        22837        -0.093691         0.035916   \n",
       "6        22778       152616         0.026915        -0.032399   \n",
       "7        28022       159890         0.028520        -0.056449   \n",
       "8        26534       168757         0.029877        -0.062642   \n",
       "9        25794       139378         0.025047        -0.021635   \n",
       "\n",
       "   minority_pos_changes  minority_neg_changes       morals  \n",
       "0                 12215                  3102       purity  \n",
       "1                  5061                  6860    authority  \n",
       "2                 11501                  4232     fairness  \n",
       "3                  1445                 14344  degradation  \n",
       "4                 13601                  3902         care  \n",
       "5                 15331                  1806      loyalty  \n",
       "6                  1773                 13037   subversion  \n",
       "7                  1150                 20679     cheating  \n",
       "8                  1073                 22308         harm  \n",
       "9                  1379                 14462     betrayal  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('3.9.1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "428fe311e7c18bbcbe168afadaa7ed4121f27507cb52005f46617a2bd5ad930b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
